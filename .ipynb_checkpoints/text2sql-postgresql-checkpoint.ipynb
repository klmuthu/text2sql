{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb548c-60e7-4929-9ae2-26113df7e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "upgrade_output = !pip install --upgrade pip\n",
    "install_boto3_output = !pip install boto3\n",
    "##Ensure your boto3 and botocore libraries are up to date\n",
    "upgrade_output_botocore_boto3= !pip install --upgrade boto3 botocore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd1122-9bee-4cde-a536-0d149b796f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created VPC: vpc-09e077a17a883fe0a\n",
      "Created subnet subnet-08f531e5681fa2bbf in us-west-2a\n",
      "Created subnet subnet-0ba3693bf9d4018d6 in us-west-2b\n",
      "Created subnet subnet-02dd4ebe83651d0f5 in us-west-2c\n",
      "Created Aurora cluster: aurora-text2sql-cluster\n",
      "Waiting for cluster to be available...\n",
      "Cluster status: creating\n"
     ]
    }
   ],
   "source": [
    "!python infra.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6a29e0a2-12ff-42f7-b1aa-8ffecf097633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "from typing import Dict, Any, List, Union\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore.config import Config\n",
    "\n",
    "# Initialize logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb84fc4-0b36-493d-a269-60959ece77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sqlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1d2ddd-b839-4fe0-9fb9-edf566807245",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_client = boto3.client('rds-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "440ad441-0550-49c5-af88-15efec549268",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_ARN = 'arn:aws:rds:us-west-2:831993209541:cluster:aurora-text2sql-cluster'\n",
    "SECRET_ARN = 'arn:aws:secretsmanager:us-west-2:831993209541:secret:rds!cluster-be97ab95-23e3-4eed-bacf-3b56ccf5ce33-56lAgn'\n",
    "DATABASE_NAME = 'ecommerce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d52f3db-5f84-44d1-9292-470afdc863a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ecommerce created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create database\n",
    "try:\n",
    "   rds_client.execute_statement(\n",
    "       resourceArn=CLUSTER_ARN,\n",
    "       secretArn=SECRET_ARN,\n",
    "       sql=f'CREATE DATABASE {DATABASE_NAME};'\n",
    "   )\n",
    "   print(f\"Database {DATABASE_NAME} created successfully\")\n",
    "except Exception as e:\n",
    "   print(f\"Database creation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19105a1b-ae33-4619-9860-88d2c9a93be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension created successfully: {'ResponseMetadata': {'RequestId': 'ad5980be-903d-4439-84d3-3b7bbb33d017', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'ad5980be-903d-4439-84d3-3b7bbb33d017', 'date': 'Fri, 13 Jun 2025 22:04:01 GMT', 'content-type': 'application/json', 'content-length': '110', 'connection': 'keep-alive'}, 'RetryAttempts': 0}, 'numberOfRecordsUpdated': 0, 'generatedFields': []}\n"
     ]
    }
   ],
   "source": [
    "# install pgvector extension\n",
    "try:\n",
    "    result = rds_client.execute_statement(\n",
    "        resourceArn=CLUSTER_ARN,\n",
    "        secretArn=SECRET_ARN,\n",
    "        database=DATABASE_NAME,\n",
    "        sql='CREATE EXTENSION IF NOT EXISTS vector;'\n",
    "    )\n",
    "    print(f\"Extension created successfully: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cfcd2744-65c2-4bf4-87e5-ef21e781bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read table schema sql file\n",
    "import sqlparse\n",
    "# Read SQL file\n",
    "with open('ecommerce_schema.sql', 'r') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "# Parse SQL into individual statements\n",
    "# RDS Data API requires executing statements one at a time\n",
    "statements = sqlparse.split(sql_content)\n",
    "\n",
    "# Filter out empty statements and comments\n",
    "# statements = [stmt.strip() for stmt in statements if stmt.strip() \n",
    "#              and not stmt.strip().startswith('--')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5352dc09-f513-4c27-b619-376dfcf49d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing statement 1/24...\n",
      "Executing statement 2/24...\n",
      "Executing statement 3/24...\n",
      "Executing statement 4/24...\n",
      "Executing statement 5/24...\n",
      "Executing statement 6/24...\n",
      "Executing statement 7/24...\n",
      "Executing statement 8/24...\n",
      "Executing statement 9/24...\n",
      "Executing statement 10/24...\n",
      "Executing statement 11/24...\n",
      "Executing statement 12/24...\n",
      "Executing statement 13/24...\n",
      "Executing statement 14/24...\n",
      "Executing statement 15/24...\n",
      "Executing statement 16/24...\n",
      "Executing statement 17/24...\n",
      "Executing statement 18/24...\n",
      "Executing statement 19/24...\n",
      "Executing statement 20/24...\n",
      "Executing statement 21/24...\n",
      "Executing statement 22/24...\n",
      "Executing statement 23/24...\n",
      "Executing statement 24/24...\n",
      "\n",
      "Execution complete: 24 successful, 0 failed\n"
     ]
    }
   ],
   "source": [
    "# create tables\n",
    "\n",
    "def execute_sql_statement(statement, transaction_id=None):\n",
    "    \"\"\"Execute a single SQL statement via RDS Data API\"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            'resourceArn': CLUSTER_ARN,\n",
    "            'secretArn': SECRET_ARN,\n",
    "            'database': DATABASE_NAME,\n",
    "            'sql': statement\n",
    "        }\n",
    "        \n",
    "        if transaction_id:\n",
    "            params['transactionId'] = transaction_id\n",
    "            \n",
    "        response = rds_client.execute_statement(**params)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing statement: {str(e)}\")\n",
    "        print(f\"Statement: {statement[:100]}...\")  # Show first 100 chars\n",
    "        raise\n",
    "\n",
    "# Execute all statements\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "for i, statement in enumerate(statements):\n",
    "    try:\n",
    "        # Skip certain statements that might need special handling\n",
    "        if statement.upper().startswith('CREATE EXTENSION'):\n",
    "            print(f\"Statement {i+1}: Creating extension...\")\n",
    "            # You might need to run this with admin privileges separately\n",
    "            \n",
    "        print(f\"Executing statement {i+1}/{len(statements)}...\")\n",
    "        execute_sql_statement(statement)\n",
    "        successful += 1\n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        print(f\"Failed on statement {i+1}: {e}\")\n",
    "        # Optionally continue or break based on your needs\n",
    "        # break\n",
    "\n",
    "print(f\"\\nExecution complete: {successful} successful, {failed} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18a417e1-8051-40b0-84c0-464f9f7923ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data SQL file\n",
    "with open('ecommerce_data.sql', 'r') as f:\n",
    "    sql_content = f.read()\n",
    "\n",
    "# Parse SQL into individual statements\n",
    "import sqlparse\n",
    "\n",
    "statements = sqlparse.split(sql_content)\n",
    "data_statements = [stmt.strip() for stmt in statements if stmt.strip() \n",
    "                  and not stmt.strip().startswith('--')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a95f6d-6ea7-418d-9930-c50b854ca0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert data\n",
    "def execute_sql_statement(statement):\n",
    "    \"\"\"Execute a single SQL statement via RDS Data API\"\"\"\n",
    "    try:\n",
    "        response = rds_client.execute_statement(\n",
    "            resourceArn=CLUSTER_ARN,\n",
    "            secretArn=SECRET_ARN,\n",
    "            database=DATABASE_NAME,\n",
    "            sql=statement\n",
    "        )\n",
    "        records_affected = response.get('numberOfRecordsUpdated', 0)\n",
    "        print(f\"    → {records_affected} records affected\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Execute all statements\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "print(f\"Found {len(data_statements)} statements to execute\\n\")\n",
    "\n",
    "for i, statement in enumerate(data_statements):\n",
    "    try:\n",
    "        stmt_type = statement.split()[0].upper() if statement.split() else \"UNKNOWN\"\n",
    "        print(f\"Executing statement {i+1}/{len(data_statements)} ({stmt_type})...\")\n",
    "        \n",
    "        execute_sql_statement(statement)\n",
    "        successful += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        print(f\"Failed on statement {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✅ Execution complete: {successful} successful, {failed} failed\")\n",
    "\n",
    "# Quick verification\n",
    "try:\n",
    "    result = rds_client.execute_statement(\n",
    "        resourceArn=CLUSTER_ARN,\n",
    "        secretArn=SECRET_ARN,\n",
    "        database=DATABASE_NAME,\n",
    "        sql=\"SELECT table_name, (SELECT COUNT(*) FROM information_schema.tables t2 WHERE t2.table_name = t1.table_name) as row_count FROM information_schema.tables t1 WHERE table_schema = 'public' AND table_type = 'BASE TABLE' ORDER BY table_name;\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📊 Table verification:\")\n",
    "    total_rows = 0\n",
    "    for record in result.get('records', []):\n",
    "        table_name = record[0]['stringValue']\n",
    "        # Get actual row count\n",
    "        count_result = rds_client.execute_statement(\n",
    "            resourceArn=CLUSTER_ARN,\n",
    "            secretArn=SECRET_ARN,\n",
    "            database=DATABASE_NAME,\n",
    "            sql=f\"SELECT COUNT(*) FROM {table_name};\"\n",
    "        )\n",
    "        row_count = count_result['records'][0][0]['longValue']\n",
    "        total_rows += row_count\n",
    "        print(f\"  {table_name}: {row_count} rows\")\n",
    "    \n",
    "    print(f\"\\n🎉 Total rows inserted: {total_rows}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Verification failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cf4ee1a5-c963-48d3-bbb7-efbde659aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Bedrock client\n",
    "model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "region = \"us-west-2\"\n",
    "\n",
    "#increase the standard time out limits in boto3, because Bedrock may take a while to respond to large requests.\n",
    "my_config = Config(\n",
    "    connect_timeout=60*5,\n",
    "    read_timeout=60*5,\n",
    ")\n",
    "bedrock = boto3.client(service_name='bedrock-runtime', region_name=region, config=my_config)\n",
    "\n",
    "# bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1a5c586e-b60f-4283-a0be-8a4876e22de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseTools:\n",
    "    def __init__(self):  # Fixed: removed asterisks\n",
    "        self.rds_data = boto3.client(\"rds-data\", region_name=region)\n",
    "    \n",
    "    def execute_sql(self, query: str) -> str:\n",
    "        \"\"\"Execute SQL query using RDS Data API and return results as formatted string\"\"\"\n",
    "        try:\n",
    "            response = self.rds_data.execute_statement(\n",
    "                resourceArn=CLUSTER_ARN,\n",
    "                secretArn=SECRET_ARN,\n",
    "                database=DATABASE_NAME,\n",
    "                sql=query,\n",
    "                includeResultMetadata=True,\n",
    "            )\n",
    "            \n",
    "            # Handle queries that don't return records (like COUNT queries)\n",
    "            if \"records\" not in response or not response[\"records\"]:\n",
    "                # For COUNT queries, check if there's a result in generatedFields\n",
    "                if \"generatedFields\" in response:\n",
    "                    return json.dumps([{\"count\": 0}])\n",
    "                return json.dumps([])  # Return empty JSON array instead of string\n",
    "            \n",
    "            # Get column names from the response\n",
    "            columns = [field[\"name\"] for field in response.get(\"columnMetadata\", [])]\n",
    "            \n",
    "            # Format results\n",
    "            formatted_results = []\n",
    "            for record in response[\"records\"]:\n",
    "                row_values = []\n",
    "                for field in record:\n",
    "                    if \"stringValue\" in field:\n",
    "                        row_values.append(str(field[\"stringValue\"]))\n",
    "                    elif \"longValue\" in field:\n",
    "                        row_values.append(str(field[\"longValue\"]))\n",
    "                    elif \"doubleValue\" in field:\n",
    "                        row_values.append(str(field[\"doubleValue\"]))\n",
    "                    elif \"booleanValue\" in field:\n",
    "                        row_values.append(str(field[\"booleanValue\"]))\n",
    "                    elif \"isNull\" in field and field[\"isNull\"]:\n",
    "                        row_values.append(\"NULL\")\n",
    "                    else:\n",
    "                        row_values.append(\"NULL\")\n",
    "                \n",
    "                row_dict = dict(zip(columns, row_values))\n",
    "                formatted_results.append(row_dict)\n",
    "            \n",
    "            return json.dumps(formatted_results, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Database error: {str(e)}\")\n",
    "            # Return empty JSON array on error instead of error string\n",
    "            return json.dumps([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9420c5ac-1ba4-487d-a6c5-0dab2b32f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful!\n",
      "Query result: [\n",
      "  {\n",
      "    \"current_timestamp\": \"2025-06-19 00:22:54.879971\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Initialize database tools\n",
    "db_tools = DatabaseTools()\n",
    "\n",
    "# Test database connection\n",
    "try:\n",
    "    result = db_tools.execute_sql(\"SELECT current_timestamp;\")\n",
    "    print(\"Database connection successful!\")\n",
    "    print(\"Query result:\", result)\n",
    "except Exception as e:\n",
    "    print(\"Database connection failed!\")\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "542b7cc1-da90-4d63-912b-2ba8b5f97488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embedding(\n",
    "    text: str,\n",
    "    model_id: str = \"amazon.titan-embed-text-v2:0\",\n",
    "    embedding_types: List[str] = [\"float\"],\n",
    ") -> Union[List[float], dict]:\n",
    "    \"\"\"Generate embeddings for the given text using Amazon Titan Embeddings V2.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to generate embeddings for\n",
    "        model_id (str): The model ID to use (default: amazon.titan-embed-text-v2:0)\n",
    "        embedding_types (List[str]): Types of embeddings to generate (default: [\"float\"])\n",
    "\n",
    "    Returns:\n",
    "        Union[List[float], dict]: The generated embeddings\n",
    "\n",
    "    Raises:\n",
    "        ClientError: If the Bedrock API call fails\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        raise ValueError(\"Input text must be a non-empty string\")\n",
    "\n",
    "    payload = {\n",
    "        \"inputText\": text,\n",
    "        \"embeddingTypes\": embedding_types,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = bedrock.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(payload),\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        body = json.loads(resp[\"body\"].read())\n",
    "    except ClientError as e:\n",
    "        logger.error(\"Bedrock error: %s\", e.response[\"Error\"][\"Message\"])\n",
    "        raise\n",
    "\n",
    "    embeds = body.get(\"embeddingsByType\", {})\n",
    "    if len(embedding_types) == 1:\n",
    "        return embeds.get(embedding_types[0], [])\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca62e41-6c03-49c8-a280-426d9de633c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"battery\"\n",
    "vector = text_to_embedding(sample)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47633120-d09e-47c6-a0ca-c8973eb70463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_missing_embeddings(\n",
    "    db_tools: DatabaseTools,\n",
    "    table: str,\n",
    "    id_col: str = \"review_id\",\n",
    "    text_col: str = \"comment\",\n",
    "    vec_col: str = \"comment_embedding\",\n",
    "    batch_size: int = 100,\n",
    ") -> None:\n",
    "    \"\"\"Populate missing embeddings for rows in the specified table.\"\"\"\n",
    "    try:\n",
    "        # 1) Count rows missing embeddings\n",
    "        count_sql = f\"SELECT COUNT(*) FROM {table} WHERE {vec_col} IS NULL\"\n",
    "        count_result = db_tools.execute_sql(count_sql)\n",
    "        \n",
    "        # Parse the JSON string result with better error handling\n",
    "        try:\n",
    "            result_list = json.loads(count_result)\n",
    "            if result_list and isinstance(result_list, list) and len(result_list) > 0:\n",
    "                # Handle different possible column names for count\n",
    "                count_dict = result_list[0]\n",
    "                total_missing = int(\n",
    "                    count_dict.get('count', count_dict.get('COUNT(*)', 0))\n",
    "                )\n",
    "            else:\n",
    "                total_missing = 0\n",
    "        except (json.JSONDecodeError, KeyError, ValueError) as e:\n",
    "            logger.error(f\"Could not parse count result: {count_result}\")\n",
    "            logger.error(f\"Parse error: {str(e)}\")\n",
    "            return\n",
    "        \n",
    "        logger.info(\"Found %d rows missing embeddings\", total_missing)\n",
    "        \n",
    "        if total_missing == 0:\n",
    "            logger.info(\"No missing embeddings to process\")\n",
    "            return\n",
    "        \n",
    "        # 2) Fetch rows missing embeddings in batches\n",
    "        offset = 0\n",
    "        while offset < total_missing:\n",
    "            select_sql = (\n",
    "                f\"SELECT {id_col}, {text_col} \"\n",
    "                f\"FROM {table} \"\n",
    "                f\"WHERE {vec_col} IS NULL \"\n",
    "                f\"ORDER BY {id_col} \"\n",
    "                f\"LIMIT {batch_size} OFFSET {offset}\"\n",
    "            )\n",
    "            \n",
    "            result = db_tools.execute_sql(select_sql)\n",
    "            \n",
    "            try:\n",
    "                rows = json.loads(result)\n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(\"Could not parse SELECT output: %s\", result)\n",
    "                logger.error(\"JSON decode error: %s\", str(e))\n",
    "                return\n",
    "            \n",
    "            if not rows:\n",
    "                break\n",
    "            \n",
    "            # 3) Process each row in the batch\n",
    "            for row in rows:\n",
    "                pk = row.get(id_col)\n",
    "                text = row.get(text_col)\n",
    "                \n",
    "                if not pk:\n",
    "                    logger.warning(\"Skipping row: missing primary key\")\n",
    "                    continue\n",
    "                \n",
    "                if not text or text.upper() == \"NULL\":\n",
    "                    logger.info(\"Skipping %s=%s: no text\", id_col, pk)\n",
    "                    continue\n",
    "                \n",
    "                # 4) Generate embedding\n",
    "                try:\n",
    "                    vec = text_to_embedding(text)\n",
    "                    if not vec:\n",
    "                        logger.warning(\n",
    "                            \"Empty embedding generated for %s=%s\", id_col, pk\n",
    "                        )\n",
    "                        continue\n",
    "                    \n",
    "                    # 5) Format as Postgres vector literal and update\n",
    "                    vec_literal = \"[\" + \",\".join(str(x) for x in vec) + \"]\"\n",
    "                    update_sql = (\n",
    "                        f\"UPDATE {table} \"\n",
    "                        f\"SET {vec_col} = '{vec_literal}'::vector \"\n",
    "                        f\"WHERE {id_col} = {pk}\"\n",
    "                    )\n",
    "                    \n",
    "                    db_tools.execute_sql(update_sql)\n",
    "                    logger.info(\"Updated embedding for %s=%s\", id_col, pk)\n",
    "                    \n",
    "                except ClientError as e:\n",
    "                    logger.error(\"Embedding failed for %s=%s: %s\", id_col, pk, str(e))\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    logger.error(\n",
    "                        \"Unexpected error processing %s=%s: %s\", id_col, pk, str(e)\n",
    "                    )\n",
    "                    continue\n",
    "            \n",
    "            offset += batch_size\n",
    "            logger.info(\"Processed %d/%d rows\", min(offset, total_missing), total_missing)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(\"Fatal error in populate_missing_embeddings: %s\", str(e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "12c86224-f7ff-40e6-92f7-9da4d520c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 23:06:14,415 - __main__ - INFO - Found 24 rows missing embeddings\n",
      "2025-06-13 23:06:14,633 - __main__ - INFO - Updated embedding for review_id=1\n",
      "2025-06-13 23:06:14,747 - __main__ - INFO - Updated embedding for review_id=2\n",
      "2025-06-13 23:06:14,854 - __main__ - INFO - Updated embedding for review_id=3\n",
      "2025-06-13 23:06:14,967 - __main__ - INFO - Updated embedding for review_id=4\n",
      "2025-06-13 23:06:15,075 - __main__ - INFO - Updated embedding for review_id=5\n",
      "2025-06-13 23:06:15,181 - __main__ - INFO - Updated embedding for review_id=6\n",
      "2025-06-13 23:06:15,277 - __main__ - INFO - Updated embedding for review_id=7\n",
      "2025-06-13 23:06:15,370 - __main__ - INFO - Updated embedding for review_id=8\n",
      "2025-06-13 23:06:15,482 - __main__ - INFO - Updated embedding for review_id=9\n",
      "2025-06-13 23:06:15,577 - __main__ - INFO - Updated embedding for review_id=10\n",
      "2025-06-13 23:06:15,687 - __main__ - INFO - Updated embedding for review_id=11\n",
      "2025-06-13 23:06:15,782 - __main__ - INFO - Updated embedding for review_id=12\n",
      "2025-06-13 23:06:15,875 - __main__ - INFO - Updated embedding for review_id=13\n",
      "2025-06-13 23:06:15,971 - __main__ - INFO - Updated embedding for review_id=14\n",
      "2025-06-13 23:06:16,077 - __main__ - INFO - Updated embedding for review_id=15\n",
      "2025-06-13 23:06:16,179 - __main__ - INFO - Updated embedding for review_id=16\n",
      "2025-06-13 23:06:16,272 - __main__ - INFO - Updated embedding for review_id=17\n",
      "2025-06-13 23:06:16,377 - __main__ - INFO - Updated embedding for review_id=18\n",
      "2025-06-13 23:06:16,472 - __main__ - INFO - Updated embedding for review_id=19\n",
      "2025-06-13 23:06:16,583 - __main__ - INFO - Updated embedding for review_id=20\n",
      "2025-06-13 23:06:16,683 - __main__ - INFO - Updated embedding for review_id=21\n",
      "2025-06-13 23:06:16,775 - __main__ - INFO - Updated embedding for review_id=22\n",
      "2025-06-13 23:06:16,873 - __main__ - INFO - Updated embedding for review_id=23\n",
      "2025-06-13 23:06:16,978 - __main__ - INFO - Updated embedding for review_id=24\n",
      "2025-06-13 23:06:16,979 - __main__ - INFO - Processed 24/24 rows\n"
     ]
    }
   ],
   "source": [
    "# 3) Run embeddings batch‐loader \n",
    "populate_missing_embeddings(\n",
    "    db_tools=db_tools,\n",
    "    table=\"ecommerce.public.reviews\",          # replace with your schema.table\n",
    "    id_col=\"review_id\",                      # only if you’ve renamed your PK\n",
    "    text_col=\"comment\",           # your text column\n",
    "    vec_col=\"comment_embedding\",  # your vector column\n",
    "    batch_size=100                    # adjust batch size as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "92781fad-9afc-469d-aec7-c693da3b2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool configuration\n",
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"execute_sql\",\n",
    "                \"description\": \"Execute SQL query against PostgreSQL database and return results\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"SQL query to execute\",\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"query\"],\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"vector_search\",\n",
    "                \"description\": \"Perform vector similarity search on review comments\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"text\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Text to search for similar comments\",\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"text\"],\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    \"toolChoice\": {\"auto\": {}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "51e71657-53ff-403b-a3ee-dc28bdcf1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse_with_tools(\n",
    "    messages: list, system: str = \"\", tool_config: Dict = tool_config\n",
    ") -> Dict:\n",
    "    \"\"\"Call Bedrock Converse API with tools\"\"\"\n",
    "    response = bedrock.converse(\n",
    "        modelId=model_id, system=system, messages=messages, toolConfig=tool_config\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "44a1cb64-2677-4b6b-9596-7e613ad190f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_vector_search(text: str) -> str:\n",
    "    \"\"\"Perform vector similarity search on review comments.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to search for similar tickets\n",
    "\n",
    "    Returns:\n",
    "        str: JSON string containing the search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embeddings for the search text\n",
    "        embeddings = text_to_embedding(text)\n",
    "\n",
    "        # Format embeddings for SQL query\n",
    "        embeddings_vector = \"[\" + \",\".join(str(x) for x in embeddings) + \"]\"\n",
    "\n",
    "        # Construct and execute the vector search query\n",
    "        query = f\"\"\"\n",
    "        SELECT rating, title, comment, pros, cons, helpful_count, not_helpful_count, admin_response, status\n",
    "        FROM ecommerce.public.reviews\n",
    "        WHERE comment IS NOT NULL\n",
    "        ORDER BY comment_embedding <-> '{embeddings_vector}'::vector\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query using DatabaseTools\n",
    "        db_tools = DatabaseTools()\n",
    "        result = db_tools.execute_sql(query)\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Error performing vector search: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "498619ac-cdd2-483b-8ef3-7d00951067ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = [\n",
    "    {\n",
    "        \"text\": \"\"\"\n",
    "SQL query assistant for e-commerce PostgreSQL database. Convert natural language to SQL and explain results.\n",
    "\n",
    "<database_overview>\n",
    "E-commerce platform with products, orders, users, reviews, and promotions.\n",
    "Special features: Vector embeddings VECTOR(1024) for semantic search, hierarchical categories, full-text search on TEXT columns.\n",
    "</database_overview>\n",
    "\n",
    "<schema>\n",
    "<table name=\"users\" pk=\"user_id\">\n",
    "email (UNIQUE), username (UNIQUE), password_hash, first_name, last_name, phone_number, \n",
    "account_status, email_verified, preferred_currency, created_at, updated_at\n",
    "</table>\n",
    "\n",
    "<table name=\"categories\" pk=\"category_id\">\n",
    "name, slug (UNIQUE), description (TEXT), parent_category_id (self-ref), is_active, sort_order\n",
    "</table>\n",
    "\n",
    "<table name=\"products\" pk=\"product_id\">\n",
    "sku (UNIQUE), name, slug (UNIQUE), description (TEXT), category_id→categories,\n",
    "price, stock_quantity, brand, weight_kg, is_active, is_featured, is_digital,\n",
    "rating_average, rating_count, sold_count, created_at\n",
    "</table>\n",
    "\n",
    "<table name=\"orders\" pk=\"order_id\">\n",
    "order_number (UNIQUE), user_id→users, order_status, payment_status,\n",
    "shipping_address_id→addresses, payment_method_id→payment_methods,\n",
    "subtotal, tax_amount, shipping_cost, discount_amount, total_amount,\n",
    "tracking_number, shipped_at, delivered_at, created_at\n",
    "</table>\n",
    "\n",
    "<table name=\"reviews\" pk=\"review_id\">\n",
    "product_id→products, user_id→users, order_id→orders, rating (1-5),\n",
    "comment (TEXT), comment_embedding VECTOR(1024), pros (TEXT), cons (TEXT),\n",
    "helpful_count, status (pending|approved|rejected), created_at\n",
    "</table>\n",
    "\n",
    "<table name=\"addresses\" pk=\"address_id\">\n",
    "user_id→users, address_type (shipping|billing), first_name, last_name,\n",
    "address_line1, city, state_province, postal_code, country_code\n",
    "</table>\n",
    "\n",
    "<table name=\"payment_methods\" pk=\"payment_method_id\">\n",
    "user_id→users, payment_type (credit_card|paypal), card_last_four, is_default\n",
    "</table>\n",
    "\n",
    "<table name=\"promotions\" pk=\"promotion_id\">\n",
    "code (UNIQUE), name, discount_type (percentage|fixed_amount), discount_value,\n",
    "start_date, end_date, is_active, usage_limit_per_customer\n",
    "</table>\n",
    "\n",
    "<table name=\"order_items\" pk=\"order_item_id\">\n",
    "order_id→orders, product_id→products, quantity, unit_price, total_price\n",
    "</table>\n",
    "\n",
    "<table name=\"product_images\" pk=\"image_id\">\n",
    "product_id→products, image_url, is_primary, sort_order\n",
    "</table>\n",
    "\n",
    "<table name=\"shipping_methods\" pk=\"shipping_method_id\">\n",
    "name, code (UNIQUE), base_cost, estimated_days_min, estimated_days_max\n",
    "</table>\n",
    "\n",
    "<table name=\"product_promotions\" pk=\"product_promotion_id\">\n",
    "product_id→products, promotion_id→promotions, UNIQUE(product_id, promotion_id)\n",
    "</table>\n",
    "</schema>\n",
    "\n",
    "<query_rules>\n",
    "- Use JOIN not comma-separated tables\n",
    "- Include LIMIT for large results\n",
    "- Use EXISTS over IN for subqueries\n",
    "- Handle NULLs with COALESCE\n",
    "- Use CTEs for complex queries\n",
    "- For semantic search: use vector_search tool\n",
    "- For regular queries: use execute_sql tool\n",
    "</query_rules>\n",
    "\n",
    "<examples>\n",
    "<example name=\"product_search\">\n",
    "Find active products under $500:\n",
    "```sql\n",
    "SELECT p.*, c.name as category \n",
    "FROM products p\n",
    "JOIN categories c ON p.category_id = c.category_id\n",
    "WHERE p.is_active = TRUE AND p.price < 500\n",
    "ORDER BY p.rating_average DESC\n",
    "LIMIT 20;\n",
    "```\n",
    "</example>\n",
    "\n",
    "<example name=\"sales_analytics\">\n",
    "Monthly sales totals:\n",
    "```sql\n",
    "SELECT DATE_TRUNC('month', created_at) as month,\n",
    "       COUNT(*) as orders, SUM(total_amount) as revenue\n",
    "FROM orders\n",
    "WHERE order_status NOT IN ('canceled', 'refunded')\n",
    "GROUP BY 1 ORDER BY 1 DESC;\n",
    "```\n",
    "</example>\n",
    "\n",
    "<example name=\"low_stock\">\n",
    "Products needing restock:\n",
    "```sql\n",
    "SELECT sku, name, stock_quantity, sold_count\n",
    "FROM products\n",
    "WHERE is_active = TRUE AND stock_quantity < 10\n",
    "ORDER BY sold_count DESC;\n",
    "```\n",
    "</example>\n",
    "</examples>\n",
    "\n",
    "<response_format>\n",
    "1. Acknowledge request\n",
    "2. Generate SQL with explanation\n",
    "3. Execute and summarize results\n",
    "4. Suggest follow-ups if relevant\n",
    "</response_format>\"\"\"\n",
    "             }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5d26ecb1-fe92-4820-9ada-36011a36194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(\n",
    "    user_question: str, conversation_history: list = None, stream_callback=None\n",
    ") -> str:\n",
    "    \"\"\"Process natural language question and return SQL results in plain English\"\"\"\n",
    "\n",
    "    # Initialize or use existing conversation history\n",
    "    if conversation_history is None:\n",
    "        conversation_history = []\n",
    "\n",
    "    # Create messages list with previous conversation history\n",
    "    messages = []\n",
    "    messages.extend(conversation_history)\n",
    "\n",
    "    # Add the current user question\n",
    "    current_user_message = {\"role\": \"user\", \"content\": [{\"text\": user_question}]}\n",
    "    messages.append(current_user_message)\n",
    "\n",
    "    # Track whether we've added the user message to history\n",
    "    user_message_added = False\n",
    "    final_assistant_response = None\n",
    "\n",
    "    while True:\n",
    "        # Call the model\n",
    "        if stream_callback:\n",
    "            logger.info(\"Using streaming mode\")\n",
    "            output = converse_with_tools(messages, system_prompt, stream=True)\n",
    "            stream = output.get(\"stream\")\n",
    "            if stream:\n",
    "                current_response = \"\"\n",
    "                current_reasoning = \"\"\n",
    "                current_signature = \"\"\n",
    "\n",
    "                for event in stream:\n",
    "                    if \"messageStart\" in event:\n",
    "                        print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "                    if \"contentBlockDelta\" in event:\n",
    "                        delta_text = event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "                        current_response += delta_text\n",
    "                        if stream_callback:\n",
    "                            stream_callback(delta_text, \"response\")\n",
    "\n",
    "                    if \"reasoningContentDelta\" in event:\n",
    "                        delta_text = event[\"reasoningContentDelta\"][\"delta\"][\"text\"]\n",
    "                        current_reasoning += delta_text\n",
    "                        if \"signature\" in event.get(\"reasoningContentDelta\", {}).get(\n",
    "                            \"delta\", {}\n",
    "                        ):\n",
    "                            current_signature = event[\"reasoningContentDelta\"][\"delta\"][\n",
    "                                \"signature\"\n",
    "                            ]\n",
    "                        if stream_callback:\n",
    "                            stream_callback(delta_text, \"reasoning\")\n",
    "\n",
    "                    if \"messageStop\" in event:\n",
    "                        print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "                        # Create the final message with complete response\n",
    "                        output_message = {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": [{\"text\": current_response}],\n",
    "                        }\n",
    "\n",
    "                        # Add reasoning content if present\n",
    "                        if current_reasoning:\n",
    "                            output_message[\"content\"].append(\n",
    "                                {\n",
    "                                    \"reasoningContent\": {\n",
    "                                        \"reasoningText\": {\n",
    "                                            \"text\": current_reasoning,\n",
    "                                            \"signature\": current_signature or \"\",\n",
    "                                        }\n",
    "                                    }\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "                        messages.append(output_message)\n",
    "\n",
    "                        # Store this as our final response from the assistant\n",
    "                        final_assistant_response = output_message\n",
    "\n",
    "                        # Add to conversation history if not already added\n",
    "                        if not user_message_added:\n",
    "                            conversation_history.append(current_user_message)\n",
    "                            user_message_added = True\n",
    "                        break\n",
    "        else:\n",
    "            output = converse_with_tools(messages, system_prompt)\n",
    "            output_message = output[\"output\"][\"message\"]\n",
    "            messages.append(output_message)\n",
    "\n",
    "            # Store this as potentially our final response\n",
    "            final_assistant_response = output_message\n",
    "\n",
    "            # Add to conversation history if not already added\n",
    "            if not user_message_added:\n",
    "                conversation_history.append(current_user_message)\n",
    "                user_message_added = True\n",
    "\n",
    "        # Check for tool use\n",
    "        tool_use_blocks = [\n",
    "            c[\"toolUse\"] for c in messages[-1][\"content\"] if \"toolUse\" in c\n",
    "        ]\n",
    "\n",
    "        if not tool_use_blocks:\n",
    "            # No more tools to process, we have our final response\n",
    "            # Add the final assistant response to the conversation history\n",
    "            conversation_history.append(final_assistant_response)\n",
    "            break\n",
    "\n",
    "        # Process each tool use block individually\n",
    "        for tool_use in tool_use_blocks:\n",
    "            tool_name = tool_use[\"name\"]\n",
    "            tool_args = tool_use[\"input\"]\n",
    "            tool_use_id = tool_use[\"toolUseId\"]\n",
    "\n",
    "            # Execute the appropriate tool\n",
    "            if tool_name == \"vector_search\":\n",
    "                try:\n",
    "                    text = tool_args.get(\"text\", \"\")\n",
    "                    print(f\"\\n[DEBUG] Performing Vector Search:\\nText: {text}\\n\")\n",
    "                    tool_response = perform_vector_search(text)\n",
    "                except Exception as e:\n",
    "                    tool_response = json.dumps(\n",
    "                        {\"error\": f\"Error in vector search: {str(e)}\"}\n",
    "                    )\n",
    "\n",
    "            elif tool_name == \"execute_sql\":\n",
    "                try:\n",
    "                    db_tools = DatabaseTools()\n",
    "                    query = tool_args.get(\"query\", \"\")\n",
    "                    print(f\"\\n[DEBUG] Executing SQL Query:\\n{query}\\n\")\n",
    "                    result = db_tools.execute_sql(**tool_args)\n",
    "                    tool_response = json.dumps({\"result\": result, \"query\": query})\n",
    "                except Exception as e:\n",
    "                    query = tool_args.get(\"query\", \"\")\n",
    "                    tool_response = json.dumps(\n",
    "                        {\"error\": f\"Error executing SQL: {str(e)}\", \"query\": query}\n",
    "                    )\n",
    "            else:\n",
    "                tool_response = f\"Unknown tool: {tool_name}\"\n",
    "\n",
    "            print(f\"\\nTool Result: {tool_response}\")\n",
    "\n",
    "            # Add tool result as a separate message to the working messages list\n",
    "            tool_message = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"toolResult\": {\n",
    "                            \"toolUseId\": tool_use_id,\n",
    "                            \"content\": [{\"text\": tool_response}],\n",
    "                            \"status\": (\n",
    "                                \"success\" if \"Error\" not in tool_response else \"error\"\n",
    "                            ),\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "            messages.append(tool_message)\n",
    "            # Note: We don't add tool messages to conversation_history\n",
    "\n",
    "    # Find text response and reasoning content from final response\n",
    "    text_response = None\n",
    "    reasoning_content = None\n",
    "\n",
    "    for content in final_assistant_response[\"content\"]:\n",
    "        if \"text\" in content:\n",
    "            text_response = content[\"text\"]\n",
    "        elif \"reasoningContent\" in content:\n",
    "            reasoning_content = content[\"reasoningContent\"]\n",
    "\n",
    "    # Return both the final response text and updated conversation history\n",
    "    return (text_response or \"No response generated.\", conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2a6be6eb-2973-4c75-a26b-d25d97c7e4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Text-to-SQL Assistant!\n",
      "Type 'exit' to quit the conversation.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question:  battery performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your question...\n"
     ]
    },
    {
     "ename": "ThrottlingException",
     "evalue": "An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mThrottlingException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[201], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[201], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing your question...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m result, conversation_history \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Print the conversation flow\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConversation Flow:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[167], line 87\u001b[0m, in \u001b[0;36mprocess_query\u001b[0;34m(user_question, conversation_history, stream_callback)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mconverse_with_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     output_message \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     89\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend(output_message)\n",
      "Cell \u001b[0;32mIn[160], line 5\u001b[0m, in \u001b[0;36mconverse_with_tools\u001b[0;34m(messages, system, tool_config)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconverse_with_tools\u001b[39m(\n\u001b[1;32m      2\u001b[0m     messages: \u001b[38;5;28mlist\u001b[39m, system: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, tool_config: Dict \u001b[38;5;241m=\u001b[39m tool_config\n\u001b[1;32m      3\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call Bedrock Converse API with tools\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mbedrock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoolConfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mThrottlingException\u001b[0m: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many tokens, please wait before trying again."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Welcome to the Text-to-SQL Assistant!\")\n",
    "    print(\"Type 'exit' to quit the conversation.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    conversation_history = []\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        question = input(\"\\nYour question: \").strip()\n",
    "\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        print(\"\\nProcessing your question...\")\n",
    "        result, conversation_history = process_query(question, conversation_history)\n",
    "\n",
    "        # Print the conversation flow\n",
    "        print(\"\\nConversation Flow:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {result}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44188a5c-9f5e-4a3e-9a2a-10bfa0665fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df8a4e-7df5-436d-8091-6d08f90e3419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
