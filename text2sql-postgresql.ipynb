{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Advanced Text-to-SQL with PostgreSQL Vector Search\n\n## Production-Ready Hybrid Database Intelligence System\n\nThis notebook demonstrates the integration of **traditional relational database operations** with **vector search capabilities** in PostgreSQL, featuring automated query strategy selection based on user intent analysis.\n\n### ðŸŽ¯ **Core Technical Demonstrations:**\n\n#### 1. **Complex Schema Text-to-SQL Generation**\n- LLM-powered natural language to SQL conversion across multi-table schemas\n- Handling hierarchical data structures, complex joins, and nested aggregations\n- Demonstrating schema comprehension for enterprise-scale database architectures\n\n#### 2. **PostgreSQL pgvector Integration** \n- Native vector storage and similarity search within PostgreSQL\n- Embedding-based semantic search on unstructured text data\n- Demonstrating RDBMS + vector database convergence in production environments\n\n#### 3. **Automated Query Strategy Selection**\n- Foundation model analysis of query intent and optimal execution path determination\n- Context-aware routing between structured SQL and semantic vector operations\n- Unified interface abstracting query complexity from end users\n\n### ðŸ—ï¸ **Database Schema Architecture**\n\nProduction-ready ecommerce schema demonstrating complex relationships:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     users       â”‚    â”‚    categories    â”‚    â”‚    products     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ user_id (PK)    â”‚    â”‚ category_id (PK) â”‚    â”‚ product_id (PK) â”‚\nâ”‚ email           â”‚    â”‚ name             â”‚    â”‚ sku             â”‚\nâ”‚ username        â”‚    â”‚ slug             â”‚    â”‚ name            â”‚\nâ”‚ first_name      â”‚    â”‚ description      â”‚    â”‚ description     â”‚\nâ”‚ last_name       â”‚    â”‚ parent_category_idâ”‚   â”‚ category_id (FK)â”‚\nâ”‚ city            â”‚    â”‚   (FK to self)   â”‚    â”‚ brand           â”‚\nâ”‚ state_province  â”‚    â”‚ product_count    â”‚    â”‚ price           â”‚\nâ”‚ total_orders    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ stock_quantity  â”‚\nâ”‚ total_spent     â”‚           â”‚                â”‚ rating_average  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                â”‚ total_sales     â”‚\n         â”‚                    â”‚                â”‚ revenue_generatedâ”‚\n         â”‚                    â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚                    â”‚                         â”‚\n         â”‚                    â”‚                         â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚     orders      â”‚    â”‚   order_items    â”‚    â”‚    reviews      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ order_id (PK)   â”‚â”€â”€â”€â”€â”‚ order_id (FK)    â”‚    â”‚ review_id (PK)  â”‚\nâ”‚ order_number    â”‚    â”‚ product_id (FK)  â”‚â”€â”€â”€â”€â”‚ product_id (FK) â”‚\nâ”‚ user_id (FK)    â”‚    â”‚ quantity         â”‚    â”‚ user_id (FK)    â”‚\nâ”‚ order_status    â”‚    â”‚ unit_price       â”‚    â”‚ order_id (FK)   â”‚\nâ”‚ payment_status  â”‚    â”‚ total_price      â”‚    â”‚ rating          â”‚\nâ”‚ total_amount    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ title           â”‚\nâ”‚ shipping_method â”‚                            â”‚ comment         â”‚\nâ”‚ created_at      â”‚                            â”‚ comment_embeddingâ”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚   (VECTOR)      â”‚\n                                               â”‚ pros            â”‚\n                                               â”‚ cons            â”‚\n                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Schema Complexity Features:**\n- **Self-referencing hierarchies**: Categories with parent/child relationships\n- **Junction table patterns**: Many-to-many order-product relationships via order_items\n- **Vector integration**: Native pgvector storage in reviews.comment_embedding\n- **Denormalized analytics**: Pre-computed aggregations for performance optimization\n- **Multi-level foreign keys**: Reviews referencing users, products, and orders\n\n### ðŸ’¡ **Technical Implementation:**\n\n1. **Hybrid Database Architecture**: PostgreSQL with pgvector extension for unified structured + vector operations\n2. **LLM Schema Comprehension**: Foundation model understanding of complex table relationships and optimal query generation\n3. **Embedding-based Similarity**: Amazon Titan text embeddings for semantic content matching\n4. **Automated Tool Selection**: Context analysis determining SQL vs vector search execution paths\n\n## Technical Prerequisites\n- AWS account with Bedrock and RDS permissions\n- Understanding of vector embeddings and similarity search concepts\n- Familiarity with PostgreSQL and complex SQL operations\n\n---",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ“¦ STEP 1: Install Required Packages",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0afb548c-60e7-4929-9ae2-26113df7e5b0",
   "metadata": {},
   "outputs": [],
   "source": "# Install required Python packages for AWS and SQL parsing\n!pip install --upgrade pip\n!pip install boto3 sqlparse"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ—ï¸ STEP 2: Deploy AWS Infrastructure\n\nThis step creates:\n- **VPC with 3 subnets** across availability zones\n- **Aurora PostgreSQL Serverless v2 cluster** with HTTP endpoint enabled\n- **Security groups** and networking configuration\n- **Secrets Manager** for database credentials\n\n**Note**: This takes ~5-10 minutes to complete",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4efd1122-9bee-4cde-a536-0d149b796f0f",
   "metadata": {},
   "outputs": [],
   "source": "# Deploy AWS infrastructure (VPC, Aurora PostgreSQL, Security Groups)\n# This script creates all necessary AWS resources for our demo\n\n# Primary method (matches AWS samples pattern)\n!python infra.py\n\n# Alternative method if the above doesn't complete properly:\n# %run infra.py"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ”§ STEP 3: Setup Database Connection",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6a29e0a2-12ff-42f7-b1aa-8ffecf097633",
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries for AWS services and database operations\nimport json\nimport boto3\nimport logging\nimport sqlparse\nfrom typing import Dict, Any, List, Union\nfrom botocore.exceptions import ClientError\nfrom botocore.config import Config\n\n# Setup logging to track our progress\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")"
  },
  {
   "cell_type": "code",
   "id": "1bb84fc4-0b36-493d-a269-60959ece77a9",
   "metadata": {},
   "outputs": [],
   "source": "# Database connection configuration\n# These values match what was created by infra.py\nCLUSTER_ARN = 'arn:aws:rds:us-west-2:831993209541:cluster:aurora-text2sql-cluster'\nSECRET_ARN = 'arn:aws:secretsmanager:us-west-2:831993209541:secret:rds!cluster-be97ab95-23e3-4eed-bacf-3b56ccf5ce33-56lAgn'\nDATABASE_NAME = 'ecommerce'  # We'll create this database for our demo\n\n# Initialize RDS Data API client (allows SQL execution without direct connections)\nrds_client = boto3.client('rds-data')"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ› ï¸ STEP 4: Create Database Schema & Load Data\n\nWe'll create a streamlined but complex ecommerce schema with 6 core tables that demonstrate:\n- **Hierarchical relationships** (categories with parent/child structure)\n- **Many-to-many relationships** (orders â†” products via junction table) \n- **Vector integration** (reviews with embedding column for semantic search)\n- **Analytics capabilities** (aggregated sales metrics and customer data)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bd1d2ddd-b839-4fe0-9fb9-edf566807245",
   "metadata": {},
   "outputs": [],
   "source": "def run_sql(query: str, database: str = None) -> dict:\n    \"\"\"\n    Execute SQL query using RDS Data API\n    This is our main function for running any SQL command\n    \"\"\"\n    try:\n        params = {\n            'resourceArn': CLUSTER_ARN,\n            'secretArn': SECRET_ARN,\n            'sql': query\n        }\n        if database:\n            params['database'] = database\n            \n        response = rds_client.execute_statement(**params)\n        return response\n    except Exception as e:\n        print(f\"SQL execution error: {e}\")\n        return {\"error\": str(e)}\n\n# Create our ecommerce database\ntry:\n    run_sql(f'CREATE DATABASE {DATABASE_NAME};')\n    print(f\"âœ… Database '{DATABASE_NAME}' created successfully\")\nexcept Exception as e:\n    print(f\"Database may already exist: {e}\")"
  },
  {
   "cell_type": "code",
   "id": "440ad441-0550-49c5-af88-15efec549268",
   "metadata": {},
   "outputs": [],
   "source": "# Enable pgvector extension for semantic search capabilities\n# pgvector allows PostgreSQL to store and search vector embeddings\ntry:\n    result = run_sql('CREATE EXTENSION IF NOT EXISTS vector;', DATABASE_NAME)\n    print(\"âœ… pgvector extension enabled successfully\")\nexcept Exception as e:\n    print(f\"Extension setup error: {e}\")"
  },
  {
   "cell_type": "code",
   "id": "2d52f3db-5f84-44d1-9292-470afdc863a1",
   "metadata": {},
   "outputs": [],
   "source": "# Create tables by reading our streamlined schema file\n# Parse SQL file into individual statements (RDS Data API requirement)\nwith open('ecommerce_schema.sql', 'r') as f:\n    schema_sql = f.read()\n\nstatements = sqlparse.split(schema_sql)\nstatements = [stmt.strip() for stmt in statements if stmt.strip()]\n\nprint(f\"Creating {len(statements)} database tables...\")\nprint(\"ðŸ“Š Schema includes: users, categories, products, orders, order_items, reviews\")\nprint(\"ðŸ”— Complex relationships: hierarchical categories, order-product junction table\")\nprint(\"ðŸ§  Vector integration: reviews.comment_embedding for semantic search\")\n\n# Execute each CREATE TABLE statement\nfor i, statement in enumerate(statements, 1):\n    try:\n        run_sql(statement, DATABASE_NAME)\n        print(f\"  âœ… Table {i} created successfully\")\n    except Exception as e:\n        print(f\"  âŒ Table {i} failed: {e}\")\n\nprint(\"âœ… Database schema creation completed!\")"
  },
  {
   "cell_type": "code",
   "id": "19105a1b-ae33-4619-9860-88d2c9a93be8",
   "metadata": {},
   "outputs": [],
   "source": "# Insert comprehensive sample data into our tables\nwith open('ecommerce_data.sql', 'r') as f:\n    data_sql = f.read()\n\ndata_statements = sqlparse.split(data_sql)\ndata_statements = [stmt.strip() for stmt in data_statements if stmt.strip()]\n\nprint(f\"Inserting sample data with {len(data_statements)} statements...\")\nprint(\"ðŸ‘¥ 15 users across different US cities with spending history\")\nprint(\"ðŸ“¦ 16 products across 8 categories (Electronics â†’ Audio/Video, Smart Devices, etc.)\")\nprint(\"ðŸ›’ 10 orders with various statuses (delivered, shipped, processing, cancelled)\")\nprint(\"â­ 13 detailed product reviews perfect for semantic search\")\n\nfor i, statement in enumerate(data_statements, 1):\n    try:\n        result = run_sql(statement, DATABASE_NAME)\n        records_affected = result.get('numberOfRecordsUpdated', 0)\n        print(f\"  âœ… Dataset {i}: {records_affected} records inserted\")\n    except Exception as e:\n        print(f\"  âŒ Dataset {i} failed: {e}\")\n\nprint(\"âœ… Sample data insertion completed!\")\nprint(\"ðŸŽ¯ Ready for complex SQL queries and semantic search demonstrations\")"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ§  STEP 5: Setup AI Models (Bedrock)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cfcd2744-65c2-4bf4-87e5-ef21e781bdc5",
   "metadata": {},
   "outputs": [],
   "source": "# Setup Amazon Bedrock for AI capabilities\n# Claude Sonnet 4.0 for intelligent text-to-SQL conversion\n# Titan Embeddings for vector generation\n\n# Configure Bedrock client with extended timeouts for large requests\nbedrock_config = Config(\n    connect_timeout=60*5,  # 5 minutes\n    read_timeout=60*5,     # 5 minutes\n)\n\nbedrock = boto3.client(\n    service_name='bedrock-runtime', \n    region_name='us-west-2', \n    config=bedrock_config\n)\n\n# Model IDs for our AI services\nCLAUDE_MODEL = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"  # For text-to-SQL\nEMBEDDING_MODEL = \"amazon.titan-embed-text-v2:0\"                # For vector search\n\nprint(\"âœ… Bedrock AI models configured successfully\")"
  },
  {
   "cell_type": "code",
   "id": "5352dc09-f513-4c27-b619-376dfcf49d60",
   "metadata": {},
   "outputs": [],
   "source": "class DatabaseTools:\n    \"\"\"Simple database helper for executing SQL queries\"\"\"\n    \n    def __init__(self):\n        self.rds_client = boto3.client(\"rds-data\", region_name='us-west-2')\n    \n    def execute_sql(self, query: str) -> str:\n        \"\"\"Execute SQL query and return results as JSON string\"\"\"\n        try:\n            response = self.rds_client.execute_statement(\n                resourceArn=CLUSTER_ARN,\n                secretArn=SECRET_ARN,\n                database=DATABASE_NAME,\n                sql=query,\n                includeResultMetadata=True,\n            )\n            \n            # Handle empty results\n            if \"records\" not in response or not response[\"records\"]:\n                return json.dumps([])\n            \n            # Get column names and format results\n            columns = [field[\"name\"] for field in response.get(\"columnMetadata\", [])]\n            results = []\n            \n            for record in response[\"records\"]:\n                row_values = []\n                for field in record:\n                    # Extract value from different field types\n                    if \"stringValue\" in field:\n                        row_values.append(field[\"stringValue\"])\n                    elif \"longValue\" in field:\n                        row_values.append(field[\"longValue\"])\n                    elif \"doubleValue\" in field:\n                        row_values.append(field[\"doubleValue\"])\n                    elif \"booleanValue\" in field:\n                        row_values.append(field[\"booleanValue\"])\n                    else:\n                        row_values.append(None)\n                \n                results.append(dict(zip(columns, row_values)))\n            \n            return json.dumps(results, indent=2)\n            \n        except Exception as e:\n            return json.dumps({\"error\": f\"Database error: {str(e)}\"})\n\n# Test database connection\ndb_tools = DatabaseTools()\nresult = db_tools.execute_sql(\"SELECT current_timestamp;\")\nprint(\"âœ… Database connection test successful\")\nprint(\"Current time:\", json.loads(result)[0][\"current_timestamp\"])"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ”¢ STEP 6: Generate Vector Embeddings for Semantic Search\n\n**Hybrid RDBMS + Vector Database Implementation:**\n\nVector embeddings convert textual content into high-dimensional numerical representations that capture semantic relationships. PostgreSQL's pgvector extension enables native vector operations within the relational database, eliminating the need for separate vector database infrastructure.\n\n**Technical Implementation:**\n- Amazon Titan Text Embeddings v2 (1024-dimensional vectors)\n- PostgreSQL VECTOR data type with cosine similarity operations\n- Semantic search on review content independent of exact keyword matching\n\nThis approach demonstrates the convergence of traditional RDBMS and vector database capabilities in production systems.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "18a417e1-8051-40b0-84c0-464f9f7923ae",
   "metadata": {},
   "outputs": [],
   "source": "def create_embedding(text: str) -> List[float]:\n    \"\"\"\n    Convert text into a vector embedding using Amazon Titan\n    Returns a list of 1024 numbers that represent the text's meaning\n    \"\"\"\n    payload = {\n        \"inputText\": text,\n        \"embeddingTypes\": [\"float\"]\n    }\n    \n    try:\n        response = bedrock.invoke_model(\n            modelId=EMBEDDING_MODEL,\n            body=json.dumps(payload),\n            accept=\"application/json\",\n            contentType=\"application/json\"\n        )\n        \n        body = json.loads(response[\"body\"].read())\n        embeddings = body.get(\"embeddingsByType\", {}).get(\"float\", [])\n        return embeddings\n        \n    except Exception as e:\n        print(f\"Embedding generation error: {e}\")\n        return []\n\n# Test embedding generation\ntest_text = \"This battery lasts a long time\"\ntest_embedding = create_embedding(test_text)\nprint(f\"âœ… Generated embedding with {len(test_embedding)} dimensions\")\nprint(f\"Sample values: {test_embedding[:5]}...\")  # Show first 5 numbers"
  },
  {
   "cell_type": "code",
   "id": "a2a95f6d-6ea7-418d-9930-c50b854ca0c5",
   "metadata": {},
   "outputs": [],
   "source": "def add_embeddings_to_reviews():\n    \"\"\"\n    Generate embeddings for all review comments and store them in the database\n    This enables semantic search on review content\n    \"\"\"\n    \n    # Step 1: Find reviews that need embeddings\n    count_query = \"SELECT COUNT(*) FROM reviews WHERE comment_embedding IS NULL\"\n    count_result = db_tools.execute_sql(count_query)\n    total_missing = json.loads(count_result)[0][\"count\"]\n    \n    print(f\"Found {total_missing} reviews needing embeddings\")\n    \n    if total_missing == 0:\n        print(\"âœ… All reviews already have embeddings!\")\n        return\n    \n    # Step 2: Get reviews without embeddings\n    select_query = \"\"\"\n        SELECT review_id, comment \n        FROM reviews \n        WHERE comment_embedding IS NULL \n        AND comment IS NOT NULL\n        ORDER BY review_id\n    \"\"\"\n    \n    result = db_tools.execute_sql(select_query)\n    reviews = json.loads(result)\n    \n    # Step 3: Generate embeddings for each review\n    for review in reviews:\n        review_id = review[\"review_id\"]\n        comment = review[\"comment\"]\n        \n        if not comment:\n            continue\n            \n        print(f\"  Processing review {review_id}...\")\n        \n        # Generate embedding\n        embedding = create_embedding(comment)\n        if not embedding:\n            continue\n            \n        # Convert to PostgreSQL vector format\n        vector_str = \"[\" + \",\".join(str(x) for x in embedding) + \"]\"\n        \n        # Update database with embedding\n        update_query = f\"\"\"\n            UPDATE reviews \n            SET comment_embedding = '{vector_str}'::vector \n            WHERE review_id = {review_id}\n        \"\"\"\n        \n        run_sql(update_query, DATABASE_NAME)\n        print(f\"    âœ… Added embedding for review {review_id}\")\n    \n    print(\"âœ… All review embeddings generated successfully!\")\n\n# Generate embeddings for all reviews\nadd_embeddings_to_reviews()"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ¤– STEP 7: Foundation Model Tool Selection System\n\n**Query Strategy Determination:**\n\nClaude Sonnet 4.0 analyzes natural language queries and automatically determines the optimal execution strategy through tool selection logic:\n\n**ðŸ“Š Structured Query Scenarios (SQL Tool Selection):**\n- Aggregation operations: \"What's the average order value by state?\"\n- Complex joins: \"Show customers with repeat purchases in Electronics\"\n- Mathematical calculations: \"Calculate profit margins by product category\"\n- Temporal analysis: \"Find order trends over the last quarter\"\n\n**ðŸ” Semantic Search Scenarios (Vector Tool Selection):**\n- Content similarity: \"Find reviews about build quality issues\"\n- Sentiment analysis: \"Show complaints about customer service\"\n- Topic clustering: \"What do users say about product durability?\"\n- Conceptual matching: Independent of exact keyword presence\n\n**ðŸŽ¯ Hybrid Query Execution:**\n- Complex scenarios may trigger multiple tool usage\n- Foundation model orchestrates sequential or parallel execution\n- Results synthesis from both structured and semantic operations\n\n**Technical Architecture:**\n- Tool specification via JSON schema definitions\n- Automated function calling based on intent classification\n- Context-aware execution path optimization",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cf4ee1a5-c963-48d3-bbb7-efbde659aac1",
   "metadata": {},
   "outputs": [],
   "source": "def semantic_search(search_text: str, limit: int = 5) -> str:\n    \"\"\"\n    Find reviews similar to the search text using vector similarity\n    Returns the most semantically similar reviews\n    \"\"\"\n    try:\n        # Generate embedding for search text\n        search_embedding = create_embedding(search_text)\n        if not search_embedding:\n            return json.dumps({\"error\": \"Could not generate embedding\"})\n        \n        # Convert to PostgreSQL vector format\n        vector_str = \"[\" + \",\".join(str(x) for x in search_embedding) + \"]\"\n        \n        # Find similar reviews using cosine distance (<-> operator)\n        query = f\"\"\"\n        SELECT \n            rating,\n            title,\n            comment,\n            pros,\n            cons,\n            helpful_count,\n            (1 - (comment_embedding <-> '{vector_str}'::vector)) as similarity_score\n        FROM reviews\n        WHERE comment IS NOT NULL \n        AND comment_embedding IS NOT NULL\n        ORDER BY comment_embedding <-> '{vector_str}'::vector\n        LIMIT {limit}\n        \"\"\"\n        \n        result = db_tools.execute_sql(query)\n        return result\n        \n    except Exception as e:\n        return json.dumps({\"error\": f\"Vector search error: {str(e)}\"})\n\n# Test vector search\ntest_search = semantic_search(\"battery problems\", limit=3)\nprint(\"âœ… Vector search test successful\")\nprint(\"Sample results:\", json.loads(test_search)[0][\"title\"] if json.loads(test_search) else \"No results\")"
  },
  {
   "cell_type": "code",
   "id": "1a5c586e-b60f-4283-a0be-8a4876e22de0",
   "metadata": {},
   "outputs": [],
   "source": "# Define the tools available to Claude\nAI_TOOLS = {\n    \"tools\": [\n        {\n            \"toolSpec\": {\n                \"name\": \"execute_sql\",\n                \"description\": \"Execute SQL queries for structured data analysis (counts, filters, joins, aggregations)\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"query\": {\n                                \"type\": \"string\",\n                                \"description\": \"SQL query to execute against the ecommerce database\"\n                            }\n                        },\n                        \"required\": [\"query\"]\n                    }\n                }\n            }\n        },\n        {\n            \"toolSpec\": {\n                \"name\": \"vector_search\",\n                \"description\": \"Perform semantic similarity search on review content to find similar topics/themes\",\n                \"inputSchema\": {\n                    \"json\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"text\": {\n                                \"type\": \"string\",\n                                \"description\": \"Text to search for semantically similar content in reviews\"\n                            }\n                        },\n                        \"required\": [\"text\"]\n                    }\n                }\n            }\n        }\n    ],\n    \"toolChoice\": {\"auto\": {}}\n}\n\nprint(\"âœ… AI tools configured - Claude can now choose between SQL and vector search!\")"
  },
  {
   "cell_type": "code",
   "id": "9420c5ac-1ba4-487d-a6c5-0dab2b32f8c0",
   "metadata": {},
   "outputs": [],
   "source": "# Foundation model system prompt with detailed schema specification\nSYSTEM_PROMPT = \"\"\"\nYou are a database query optimization system with automated tool selection for hybrid SQL and vector search operations.\n\nSCHEMA SPECIFICATION (6-table ecommerce system):\n\n**users** (customer analytics):\n- user_id, email, username, first_name, last_name, city, state_province\n- total_orders, total_spent (denormalized aggregations)\n\n**categories** (hierarchical taxonomy):\n- category_id, name, slug, description, parent_category_id (self-referencing FK)\n- product_count (computed metric)\n\n**products** (catalog with analytics):\n- product_id, sku, name, description, category_id (FK to categories)\n- brand, price, cost, stock_quantity, weight_kg\n- rating_average, rating_count, total_sales, revenue_generated (computed metrics)\n\n**orders** (transaction management):\n- order_id, order_number, user_id (FK to users)\n- order_status, payment_status, shipping_address, payment_method, shipping_method\n- subtotal, tax_amount, shipping_cost, discount_amount, total_amount\n- shipped_at, delivered_at, created_at\n\n**order_items** (junction table):\n- order_item_id, order_id (FK), product_id (FK)\n- quantity, unit_price, discount_amount, tax_amount, total_price\n\n**reviews** (with vector search capability):\n- review_id, product_id (FK), user_id (FK), order_id (FK)\n- rating, title, comment, comment_embedding (VECTOR(1024) for semantic search)\n- pros, cons, is_verified_purchase, helpful_count\n\nRELATIONSHIP PATTERNS:\n- Self-referencing: categories.parent_category_id\n- One-to-many: usersâ†’orders, productsâ†’reviews, categoriesâ†’products\n- Many-to-many: ordersâ†”products via order_items junction\n- Multi-reference: reviews link to users, products, and orders\n\nTOOL SELECTION LOGIC:\n1. execute_sql for:\n   - Quantitative analysis, aggregations, mathematical operations\n   - Multi-table joins, hierarchical queries, temporal analysis\n   - Structured data filtering, sorting, grouping operations\n   - Performance metrics, business intelligence queries\n\n2. vector_search for:\n   - Semantic similarity operations on reviews.comment field\n   - Content-based analysis independent of exact keywords\n   - Sentiment and topic analysis of unstructured text\n   - Conceptual matching and thematic clustering\n\n3. Multi-tool execution for complex analytical requirements\n\nOUTPUT REQUIREMENTS:\n1. Specify tool selection rationale\n2. Present results with technical accuracy\n3. Identify relevant patterns and insights in the data\n\"\"\"\n\nprint(\"âœ… Foundation model configured with comprehensive schema specification\")\nprint(\"ðŸ”§ Tool selection logic optimized for hybrid query execution\")"
  },
  {
   "cell_type": "code",
   "id": "542b7cc1-da90-4d63-912b-2ba8b5f97488",
   "metadata": {},
   "outputs": [],
   "source": "def ask_ai(question: str) -> str:\n    \"\"\"\n    Send a question to Claude Sonnet 4.0 and handle tool execution\n    Claude will automatically choose between SQL and vector search\n    Handles multiple rounds of tool calls until completion\n    \"\"\"\n    \n    # Create the conversation\n    messages = [{\"role\": \"user\", \"content\": [{\"text\": question}]}]\n    \n    try:\n        # Continue conversation until Claude stops requesting tools\n        max_turns = 10  # Prevent infinite loops\n        turn_count = 0\n        \n        while turn_count < max_turns:\n            turn_count += 1\n            \n            # Send to Claude with tools\n            response = bedrock.converse(\n                modelId=CLAUDE_MODEL,\n                system=[{\"text\": SYSTEM_PROMPT}],\n                messages=messages,\n                toolConfig=AI_TOOLS\n            )\n            \n            assistant_message = response[\"output\"][\"message\"]\n            messages.append(assistant_message)\n            \n            # Check if Claude wants to use tools\n            tool_uses = [content for content in assistant_message[\"content\"] if \"toolUse\" in content]\n            \n            if tool_uses:\n                # Execute each tool Claude requested\n                for tool_use in tool_uses:\n                    tool_name = tool_use[\"toolUse\"][\"name\"]\n                    tool_input = tool_use[\"toolUse\"][\"input\"]\n                    tool_id = tool_use[\"toolUse\"][\"toolUseId\"]\n                    \n                    print(f\"ðŸ”§ Claude is using: {tool_name}\")\n                    \n                    # Execute the appropriate tool\n                    if tool_name == \"execute_sql\":\n                        tool_result = db_tools.execute_sql(tool_input[\"query\"])\n                        print(f\"ðŸ“Š SQL Query: {tool_input['query']}\")\n                        \n                    elif tool_name == \"vector_search\":\n                        tool_result = semantic_search(tool_input[\"text\"])\n                        print(f\"ðŸ” Searching for: {tool_input['text']}\")\n                    \n                    # Send tool result back to Claude\n                    tool_message = {\n                        \"role\": \"user\",\n                        \"content\": [{\n                            \"toolResult\": {\n                                \"toolUseId\": tool_id,\n                                \"content\": [{\"text\": tool_result}]\n                            }\n                        }]\n                    }\n                    messages.append(tool_message)\n                \n                # Continue the loop to let Claude process results and potentially make more tool calls\n                continue\n            \n            else:\n                # No tools needed, extract and return the final response\n                final_content = assistant_message[\"content\"]\n                text_response = next((c[\"text\"] for c in final_content if \"text\" in c), \"\")\n                return text_response\n        \n        # If we hit max turns, return what we have\n        return \"Response completed after maximum tool execution rounds.\"\n            \n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\nprint(\"âœ… Enhanced LLM assistant ready with multi-round tool execution support!\")\nprint(\"ðŸ”„ Now handles follow-up tool calls and complex multi-step reasoning\")"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸš€ STEP 8: Technical Demonstrations\n\n### Demo 1: Complex Schema Text-to-SQL Generation\n**Objective:** Validate LLM comprehension of multi-table relationships and automated SQL generation for complex analytical queries.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8ca62e41-6c03-49c8-a280-426d9de633c6",
   "metadata": {},
   "outputs": [],
   "source": "# DEMO 1: Complex Schema Text-to-SQL Generation\nprint(\"=\" * 70)\nprint(\"DEMO 1: Complex Schema Text-to-SQL Generation\")\nprint(\"=\" * 70)\n\n# Test multi-table join with hierarchical traversal and aggregation\nquestion1 = \"Show me the top 3 customers by total spending, including their order count and favorite product category\"\nprint(f\"Query: {question1}\")\nprint(\"\\nðŸ”§ Expected: Multi-table JOIN across users, orders, order_items, products, categories\")\nprint(\"ðŸ“Š Complexity: Aggregation + hierarchical category resolution + ranking\")\nprint(\"\\nExecution:\")\nanswer1 = ask_ai(question1)\nprint(answer1)\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "source": "### Demo 2: PostgreSQL Vector Search Implementation\n**Objective:** Demonstrate native vector operations within PostgreSQL using pgvector for semantic similarity search on unstructured content.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "47633120-d09e-47c6-a0ca-c8973eb70463",
   "metadata": {},
   "outputs": [],
   "source": "# DEMO 2: PostgreSQL Vector Search Implementation\nprint(\"DEMO 2: PostgreSQL Vector Search Implementation\")\nprint(\"=\" * 70)\n\nquestion2 = \"Find reviews about battery life issues and charging problems\"\nprint(f\"Query: {question2}\")\nprint(\"\\nðŸ”§ Expected: Vector similarity search using pgvector cosine distance\")\nprint(\"ðŸ“Š Operation: Embedding generation + semantic matching on reviews.comment_embedding\")\nprint(\"ðŸŽ¯ Capability: Content similarity independent of exact keyword presence\")\nprint(\"\\nExecution:\")\nanswer2 = ask_ai(question2)\nprint(answer2)\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "source": "### Demo 3: Automated Query Strategy Selection\n**Objective:** Validate foundation model capability to analyze query intent and select optimal execution strategy between SQL and vector operations.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "12c86224-f7ff-40e6-92f7-9da4d520c895",
   "metadata": {},
   "outputs": [],
   "source": "# DEMO 3: Automated Query Strategy Selection\nprint(\"DEMO 3: Automated Query Strategy Selection\")\nprint(\"=\" * 70)\n\n# Ambiguous query that could use either approach\nquestion3 = \"What are the main product quality issues customers mention in their reviews?\"\nprint(f\"Query: {question3}\")\nprint(\"\\nðŸ¤” Strategy Options:\")\nprint(\"   ðŸ“Š SQL Approach: Aggregate review ratings and identify low-rated products\")\nprint(\"   ðŸ” Vector Approach: Semantic search for quality-related content themes\") \nprint(\"   ðŸŽ¯ Hybrid Approach: Combine structured filtering with content analysis\")\nprint(\"\\nðŸ”§ Foundation Model Decision Process:\")\nprint(\"\\nExecution:\")\nanswer3 = ask_ai(question3)\nprint(answer3)\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ’¬ Interactive Query Testing\n\n**Technical Validation Environment**\n\nTest the foundation model's query strategy selection across different analytical scenarios. The system will demonstrate automated tool selection based on query characteristics and optimal execution path determination.\n\n**Structured Query Test Cases:**\n\n**ðŸ“Š Complex SQL Operations:**\n- \"Calculate profit margins by hierarchical product category\"\n- \"Identify customers with highest purchase frequency in Texas\"\n- \"Analyze order value distribution across payment methods\"\n- \"Show temporal trends in Electronics subcategory sales\"\n\n**ðŸ” Vector Similarity Operations:**\n- \"Find reviews discussing build quality and manufacturing defects\"\n- \"Locate customer feedback about shipping and logistics issues\"\n- \"Identify content related to product longevity and durability concerns\"\n- \"Search for mentions of value proposition and pricing feedback\"\n\n**ðŸŽ¯ Complex Analytical Scenarios:**\n- \"Which products receive the most quality-related complaints?\"\n- \"Analyze sentiment patterns across different customer segments\"\n- \"Find correlation between product price points and satisfaction themes\"",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "92781fad-9afc-469d-aec7-c693da3b2fe6",
   "metadata": {},
   "outputs": [],
   "source": "# Interactive Query Testing Environment\nprint(\"ðŸ”§ Foundation Model Query Strategy Testing\")\nprint(\"Enter queries to validate automated tool selection logic. Type 'quit' to exit.\")\nprint(\"\\nðŸ“‹ Test Categories:\")\n\nprint(\"\\nðŸ“Š Structured Data Operations:\")\nprint(\"â€¢ 'Which product categories have the highest profit margins?'\")\nprint(\"â€¢ 'Show customer geographic distribution by total spending'\")\nprint(\"â€¢ 'Analyze order completion rates by shipping method'\")\n\nprint(\"\\nðŸ” Semantic Content Analysis:\")\nprint(\"â€¢ 'Find reviews about products being difficult to use or setup'\")\nprint(\"â€¢ 'Locate feedback about customer support experiences'\")\nprint(\"â€¢ 'Search for mentions of product packaging and presentation'\")\n\nprint(\"\\nðŸŽ¯ Hybrid Analysis Scenarios:\")\nprint(\"â€¢ 'Identify top-selling products with usability complaints'\")\nprint(\"â€¢ 'Find high-value customers who mention quality concerns'\")\n\nprint(\"-\" * 70)\n\nwhile True:\n    question = input(\"\\nðŸ” Query: \").strip()\n    \n    if question.lower() == 'quit':\n        print(\"âœ… Query testing session completed\")\n        break\n    \n    if question:\n        print(f\"\\nðŸ“ Processing: {question}\")\n        print(\"âš™ï¸  Analyzing query intent and determining execution strategy...\")\n        answer = ask_ai(question)\n        print(f\"\\nðŸ“Š Result: {answer}\")\n        print(\"-\" * 70)"
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ§¹ STEP 9: Cleanup (Optional)\nRun this to delete all AWS resources and avoid charges",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "51e71657-53ff-403b-a3ee-dc28bdcf1188",
   "metadata": {},
   "outputs": [],
   "source": "# Cleanup AWS resources to avoid ongoing charges\n# This will delete the Aurora cluster, VPC, and all related resources\n# Uncomment the line below when you're done with the demo\n\n# Primary method:\n# !python clean.py\n\n# Alternative method:\n# %run clean.py\n\nprint(\"âš ï¸  Uncomment one of the lines above to cleanup AWS resources when done\")\nprint(\"ðŸ’¡ This deletes the Aurora cluster, VPC, and all related resources\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}